{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmVlYKRGDgLN",
        "outputId": "3ef9788c-c2bb-439c-c049-c14b396c87f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-CM4PclCnjW",
        "outputId": "93cb4dc8-854b-41a8-bcba-51f2c71adfc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xltAaAL2D7cp",
        "outputId": "881129d3-d27d-4bc8-d29a-b25afdeb159a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824028 sha256=68670ce19b3819cc536b6ec04ccc27d541c911df992da207483d8b9b992d60cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/e3/9b/0525ce8a69478916513509d43693511463c6468db0de237c86\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.7\n",
            "    Uninstalling py4j-0.10.9.7:\n",
            "      Successfully uninstalled py4j-0.10.9.7\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "import pyspark\n",
        "findspark.find()"
      ],
      "metadata": {
        "id": "C7X-mWve4Mr-",
        "outputId": "1f08a770-9c7f-4be3-f0cf-6155a407e307",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/usr/local/lib/python3.9/dist-packages/pyspark'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import polyfit\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext,SparkConf,SQLContext\n",
        "conf = SparkConf().setMaster('local').setAppName('ML_learning')\n",
        "sc = SparkContext.getOrCreate();\n",
        "sqlcontext = SQLContext(sc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0324xdpRMvl",
        "outputId": "fc75ccb0-691e-46b4-85f6-1a278583daa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XYqUSDlJRMpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from pyspark.sql import SparkSession\n",
        "# import pyspark.sql.functions as F\n",
        "# from pyspark import SparkContext,SparkConf,SQLContext\n",
        "# conf = SparkConf().setMaster('local').setAppName('ML_learning')\n",
        "# sc = SparkContext.getOrCreate();\n",
        "# sqlcontext = SQLContext(sc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqP4BVYcD7ad",
        "outputId": "2d4d205a-81ec-4a3f-d305-561686b5d6dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing dataset\n",
        "df = sqlcontext.read.csv(path='/content/drive/MyDrive/Colab Notebooks/CKDDataSet_original.csv',\n",
        "header = True, inferSchema = True)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yz0lCQLaD7WT",
        "outputId": "aee0d5d7-3195-4d24-8545-1cd3721866dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+-----+---+---+--------+-------+--------------------+----------+---+---+----+---+---+----+---+-----+---+---+---+---+-----+---+---+-------+\n",
            "|age| bp|   sg| al| su|     rbc|     pc|                 pcc|        ba|bgr| bu|  sc|sod|pot|hemo|pcv|   wc| rc|htn| dm|cad|appet| pe|ane|predict|\n",
            "+---+---+-----+---+---+--------+-------+--------------------+----------+---+---+----+---+---+----+---+-----+---+---+---+---+-----+---+---+-------+\n",
            "| 40|150| 1.02|  1|  0|  normal| normal|         not present|notpresent|181| 96| 8.4|135|4.0|10.3| 44| 7800|5.2|yes|yes| no| good| no| no|    ckd|\n",
            "| 45|140| 1.02|  4|  0|  normal| normal|not present         |notpresent|121| 73| 7.3|130|5.4| 9.4| 38| 6000|3.9| no| no| no| good| no|yes|    ckd|\n",
            "| 16|160| 1.02|  2|  3|  normal| normal|         not present|notpresent|423|111| 7.0|129|4.9|10.6| 31| 7500|4.6| no|yes| no| poor| no| no|    ckd|\n",
            "| 18|140|1.005|  4|  0|  normal|abnomal|             present|notpresent|106|119|11.6|131|5.5| 7.2| 32| 6700|4.4|yes| no| no| poor|yes|yes|    ckd|\n",
            "| 51|170| 1.01|  2|  0|  normal| normal|             present|notpresent| 66|144|16.0|128|5.6| 9.6| 35| 7300|5.0| no| no| no| good| no|yes|    ckd|\n",
            "| 30|160|1.015|  3|  0|  normal| normal|         not present|notpresent| 74| 84| 9.0|137|4.6| 9.6| 39| 7800|4.0|yes| no| no| good|yes|yes|    ckd|\n",
            "| 25|170| 1.01|  0|  0|  normal| normal|         not present|notpresent|100|167|14.7|127|5.8| 9.7| 36| 6900|3.7| no| no| no| good| no|yes|    ckd|\n",
            "| 35|120|1.015|  2|  4|  normal|abnomal|         not present|notpresent|410|214|17.6|132|5.6| 9.5| 44|12100|3.8| no|yes| no| good|yes|yes|    ckd|\n",
            "| 37|130| 1.02|  3|  0|  normal|abnomal|         not present|notpresent|138|182|14.8|133|5.4| 9.3| 33| 4500|3.4|yes| no| no| good| no|yes|    ckd|\n",
            "| 40|130|1.025|  2|  0|abnormal|abnomal|         not present|notpresent| 70|118| 9.4|130|5.4| 8.5| 29|12200|2.6|yes| no| no| good| no|yes|    ckd|\n",
            "| 35|120| 1.01|  2|  4|abnormal|abnomal|         not present|notpresent|490|132| 8.0|130|5.7| 8.0| 28|11000|2.8|yes|yes| no| poor| no|yes|    ckd|\n",
            "| 28|100|1.015|  3|  0|abnormal|abnomal|         not present|notpresent|138|119|11.6|135|4.0| 8.1| 32| 3800|4.3|yes| no| no| good|yes|yes|    ckd|\n",
            "| 60|160| 1.01|  3|  1|  normal| normal|         not present|notpresent| 70| 85| 5.7|142|4.9| 7.8| 28|11400|3.7|yes| no|yes| poor|yes|yes|    ckd|\n",
            "| 20|130|1.015|  2|  0|  normal| normal|         not present|notpresent|380|200|17.5|139|5.3|10.3| 33| 5300|3.2|yes|yes|yes| poor|yes| no|    ckd|\n",
            "| 20|150|1.025|  0|  1|abnormal|abnomal|         not present|   present|208|204|18.4|131|3.7|10.0| 16| 9200|3.6|yes|yes|yes| poor|yes| no|    ckd|\n",
            "| 20|140|1.025|  0|  2|abnormal| normal|         not present|notpresent| 98| 73| 7.3|129|4.9| 9.1| 24| 6200|3.4|yes| no| no| poor|yes|yes|    ckd|\n",
            "| 40|130| 1.02|  0|  0|  normal| normal|         not present|notpresent|157| 78| 6.3|130|5.0|11.7| 37| 6900|5.2| no| no| no| good| no| no|    ckd|\n",
            "| 45|120| 1.02|  3|  0|  normal| normal|         not present|notpresent| 76|119| 6.4|134|4.4|11.6| 30|11400|3.9|yes| no| no| good| no| no|    ckd|\n",
            "| 51|140| 1.02|  2|  0|  normal| normal|             present|notpresent| 99|213| 7.1|135|5.7| 8.4| 24| 5300|4.6|yes|yes|yes| poor| no|yes|    ckd|\n",
            "| 22|120| 1.02|  0|  3|  normal| normal|             present|notpresent|114|204|18.4|129|4.1|11.6| 32| 9200|4.4|yes|yes|yes| good| no| no|    ckd|\n",
            "+---+---+-----+---+---+--------+-------+--------------------+----------+---+---+----+---+---+----+---+-----+---+---+---+---+-----+---+---+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.distinct().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTlUVjVFmyCB",
        "outputId": "b268d3f3-e803-48fa-bf7d-181f41ef1c89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+-----+---+---+--------+--------+-----------+----------+---+---+----+---+---+----+---+-----+---+---+---+---+-----+---+---+-------+\n",
            "|age| bp|   sg| al| su|     rbc|      pc|        pcc|        ba|bgr| bu|  sc|sod|pot|hemo|pcv|   wc| rc|htn| dm|cad|appet| pe|ane|predict|\n",
            "+---+---+-----+---+---+--------+--------+-----------+----------+---+---+----+---+---+----+---+-----+---+---+---+---+-----+---+---+-------+\n",
            "| 41|160| 1.02|  2|  0|abnormal|  normal|not present|notpresent|115|146|11.4|136|5.0| 9.3| 39| 6200|5.2|yes|yes| no| good|yes|yes|    ckd|\n",
            "| 56| 80|1.025|  0|  0|  normal|  normal| notpresent|notpresent|131| 10| 0.5|146|3.9|13.0| 43| 7500|6.3| no| no| no| good| no| no|not ckd|\n",
            "| 31|140|1.005|  4|  1|  normal|  normal|not present|   present|141|106| 6.1|130|4.7|10.5| 44| 8500|5.2|yes|yes|yes| good|yes| no|    ckd|\n",
            "| 48|130|1.025|  4|  2|abnormal|  normal|not present|notpresent|100| 34| 5.4|131|6.0| 7.6| 24| 5300|4.6|yes| no| no| good|yes|yes|    ckd|\n",
            "| 48|120|1.005|  0|  0|abnormal|abnormal|    present|notpresent|192| 84| 9.0|129|4.9| 9.7| 24| 6200|3.4|yes|yes| no| poor| no|yes|    ckd|\n",
            "| 56|170| 1.02|  0|  0|abnormal|abnormal|not present|notpresent|281|185| 3.9|129|5.6| 8.2| 32| 9200|4.4|yes|yes| no| good| no|yes|    ckd|\n",
            "| 47| 70| 1.02|  0|  0|  normal|  normal| notpresent|notpresent|119| 46| 0.7|141|4.9|14.0| 50| 9000|5.6| no| no| no| good| no| no|not ckd|\n",
            "| 24| 70| 1.02|  0|  0|  normal|  normal| notpresent|notpresent|108| 25| 1.0|144|5.0|14.8| 45| 5800|6.4| no| no| no| good| no| no|not ckd|\n",
            "| 37| 70|1.025|  0|  0|  normal|  normal| notpresent|notpresent| 87| 38| 0.5|144|4.8|16.9| 45|10300|5.4| no| no| no| good| no| no|not ckd|\n",
            "| 25|160|1.025|  2|  3|abnormal|  normal|not present|notpresent|150|230|14.5|137|4.9| 6.3| 36| 7700|4.4|yes|yes|yes| good| no|yes|    ckd|\n",
            "| 43|160|1.005|  2|  0|  normal|  normal|not present|notpresent|224|119| 6.3|141|6.7|10.5| 32| 3800|4.3|yes|yes| no| good| no| no|    ckd|\n",
            "| 51|150|1.025|  0|  2|abnormal|abnormal|not present|   present|108|324|18.7|127|5.9| 7.3| 32| 6200|5.0|yes| no|yes| good|yes|yes|    ckd|\n",
            "| 28|120| 1.02|  4|  0|  normal|abnormal|not present|notpresent|157| 78| 6.3|130|5.0| 6.5| 28|11000|2.8| no|yes| no| good|yes|yes|    ckd|\n",
            "| 41| 60|1.025|  0|  0|  normal|  normal| notpresent|notpresent|116| 26| 1.2|135|4.9|16.8| 50| 6300|5.9| no| no| no| good| no| no|not ckd|\n",
            "| 23| 80| 1.02|  0|  0|  normal|  normal| notpresent|notpresent|130| 41| 0.9|141|4.4|14.0| 42| 7000|5.2| no| no| no| good| no| no|not ckd|\n",
            "| 25| 70|1.025|  0|  0|  normal|  normal| notpresent|notpresent|109| 47| 1.1|141|4.9|16.1| 44| 5200|5.4| no| no| no| good| no| no|not ckd|\n",
            "| 37|130| 1.02|  3|  0|  normal| abnomal|not present|notpresent|138|182|14.8|133|5.4| 9.3| 33| 4500|3.4|yes| no| no| good| no|yes|    ckd|\n",
            "| 35|150| 1.02|  0|  1|  normal|abnormal|not present|notpresent| 98| 73| 7.3|129|4.9| 9.8| 29|12200|2.6| no| no| no| poor| no|yes|    ckd|\n",
            "| 35|120| 1.01|  0|  0|  normal|abnormal|not present|   present|165|177| 5.6|128|5.6| 9.2| 36| 9800|4.4| no|yes| no| poor| no|yes|    ckd|\n",
            "| 67|160|1.005|  0|  3|abnormal|  normal|    present|   present| 94|204|18.4|130|4.3| 9.6| 37| 4500|3.4| no| no| no| good|yes| no|    ckd|\n",
            "+---+---+-----+---+---+--------+--------+-----------+----------+---+---+----+---+---+----+---+-----+---+---+---+---+-----+---+---+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL3sbLW_nOff",
        "outputId": "0653926f-b7e4-469c-9d84-ddd7eb3c14dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['age',\n",
              " 'bp',\n",
              " 'sg',\n",
              " 'al',\n",
              " 'su',\n",
              " 'rbc',\n",
              " 'pc',\n",
              " 'pcc',\n",
              " 'ba',\n",
              " 'bgr',\n",
              " 'bu',\n",
              " 'sc',\n",
              " 'sod',\n",
              " 'pot',\n",
              " 'hemo',\n",
              " 'pcv',\n",
              " 'wc',\n",
              " 'rc',\n",
              " 'htn',\n",
              " 'dm',\n",
              " 'cad',\n",
              " 'appet',\n",
              " 'pe',\n",
              " 'ane',\n",
              " 'predict']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75Par38gnYEX",
        "outputId": "91b9c2cc-320d-421a-a034-49d08999c4c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- bp: integer (nullable = true)\n",
            " |-- sg: double (nullable = true)\n",
            " |-- al: integer (nullable = true)\n",
            " |-- su: integer (nullable = true)\n",
            " |-- rbc: string (nullable = true)\n",
            " |-- pc: string (nullable = true)\n",
            " |-- pcc: string (nullable = true)\n",
            " |-- ba: string (nullable = true)\n",
            " |-- bgr: integer (nullable = true)\n",
            " |-- bu: integer (nullable = true)\n",
            " |-- sc: double (nullable = true)\n",
            " |-- sod: integer (nullable = true)\n",
            " |-- pot: double (nullable = true)\n",
            " |-- hemo: double (nullable = true)\n",
            " |-- pcv: integer (nullable = true)\n",
            " |-- wc: integer (nullable = true)\n",
            " |-- rc: double (nullable = true)\n",
            " |-- htn: string (nullable = true)\n",
            " |-- dm: string (nullable = true)\n",
            " |-- cad: string (nullable = true)\n",
            " |-- appet: string (nullable = true)\n",
            " |-- pe: string (nullable = true)\n",
            " |-- ane: string (nullable = true)\n",
            " |-- predict: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator"
      ],
      "metadata": {
        "id": "yjL5a8JTs0rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2 =df.select(df.age,df.bp.alias('label'))\n",
        "train, test = data2.randomSplit([0.9,0.1])"
      ],
      "metadata": {
        "id": "6emVqixRtAWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "metadata": {
        "id": "HUXP1Fk1R5e5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assembler=VectorAssembler().setInputCols(['age',]).setOutputCol('features')\n",
        "train01 = assembler.transform(train)\n",
        "train02 = train01.select(\"features\",\"label\")\n",
        "train02.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abTOnDf0tKEt",
        "outputId": "94bae7c6-0633-4f0b-b037-69b86da93d24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+\n",
            "|features|label|\n",
            "+--------+-----+\n",
            "|  [14.0]|  130|\n",
            "|  [15.0]|   60|\n",
            "|  [16.0]|  120|\n",
            "|  [16.0]|  160|\n",
            "|  [18.0]|  140|\n",
            "+--------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression()\n",
        "model = lr.fit(train02)"
      ],
      "metadata": {
        "id": "fIT1ARaytZzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test01 = assembler.transform(test)\n",
        "test02 = test01.select('features', 'label')\n",
        "test03 = model.transform(test02)\n",
        "test03.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtqZ8Ddqtb79",
        "outputId": "d8a0edec-0b22-4845-da17-808d4470f653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+------------------+\n",
            "|features|label|        prediction|\n",
            "+--------+-----+------------------+\n",
            "|  [20.0]|   60|129.50805795702323|\n",
            "|  [23.0]|  140| 128.7469682369734|\n",
            "|  [23.0]|  150| 128.7469682369734|\n",
            "|  [24.0]|   70| 128.4932716636235|\n",
            "|  [25.0]|  120|128.23957509027355|\n",
            "+--------+-----+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install chart_studio"
      ],
      "metadata": {
        "id": "f6sQqHfbtxpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import chart_studio.plotly as py\n",
        "# import plotly.graph_objects as go\n",
        "# fig = go.Figure()\n",
        "# fig.add_trace(go.Scatter(x=x,y=y,mode='markers',name='Original_Test',))\n",
        "# fig.add_trace(go.Scatter(x=x,y=y_pred,name='Predicted'))\n",
        "# fig.update_layout(\n",
        "# title=\"Linear Regression\",\n",
        "# xaxis_title=\"Displacement\",\n",
        "# yaxis_title=\"Horse Power\",\n",
        "# font=dict(\n",
        "# family=\"Courier New, monospace\",\n",
        "# size=18,\n",
        "# color=\"#7f7f7f\"\n",
        "# )\n",
        "# )\n",
        "# fig.show()"
      ],
      "metadata": {
        "id": "WxWvpYQstjVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = RegressionEvaluator()\n",
        "print(evaluator.evaluate(test03,\n",
        "{evaluator.metricName: \"r2\"})\n",
        ")\n",
        "print(evaluator.evaluate(test03,\n",
        "{evaluator.metricName: \"mse\"})\n",
        ")\n",
        "print(evaluator.evaluate(test03,\n",
        "{evaluator.metricName: \"rmse\"})\n",
        ")\n",
        "print(evaluator.evaluate(test03,\n",
        "{evaluator.metricName: \"mae\"})\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqR78spyuFe0",
        "outputId": "a99fb9aa-5854-4483-a01b-b54053042572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.08431095915528997\n",
            "1476.5085401263523\n",
            "38.425363240005325\n",
            "33.001053901979446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bVy0qObuiNX",
        "outputId": "4433bbe3-accb-4ef2-943b-2c9f17ff7421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+-----+---+---+--------+-------+--------------------+----------+---+---+----+---+---+----+---+-----+---+---+---+---+-----+---+---+-------+\n",
            "|age| bp|   sg| al| su|     rbc|     pc|                 pcc|        ba|bgr| bu|  sc|sod|pot|hemo|pcv|   wc| rc|htn| dm|cad|appet| pe|ane|predict|\n",
            "+---+---+-----+---+---+--------+-------+--------------------+----------+---+---+----+---+---+----+---+-----+---+---+---+---+-----+---+---+-------+\n",
            "| 40|150| 1.02|  1|  0|  normal| normal|         not present|notpresent|181| 96| 8.4|135|4.0|10.3| 44| 7800|5.2|yes|yes| no| good| no| no|    ckd|\n",
            "| 45|140| 1.02|  4|  0|  normal| normal|not present         |notpresent|121| 73| 7.3|130|5.4| 9.4| 38| 6000|3.9| no| no| no| good| no|yes|    ckd|\n",
            "| 16|160| 1.02|  2|  3|  normal| normal|         not present|notpresent|423|111| 7.0|129|4.9|10.6| 31| 7500|4.6| no|yes| no| poor| no| no|    ckd|\n",
            "| 18|140|1.005|  4|  0|  normal|abnomal|             present|notpresent|106|119|11.6|131|5.5| 7.2| 32| 6700|4.4|yes| no| no| poor|yes|yes|    ckd|\n",
            "| 51|170| 1.01|  2|  0|  normal| normal|             present|notpresent| 66|144|16.0|128|5.6| 9.6| 35| 7300|5.0| no| no| no| good| no|yes|    ckd|\n",
            "| 30|160|1.015|  3|  0|  normal| normal|         not present|notpresent| 74| 84| 9.0|137|4.6| 9.6| 39| 7800|4.0|yes| no| no| good|yes|yes|    ckd|\n",
            "| 25|170| 1.01|  0|  0|  normal| normal|         not present|notpresent|100|167|14.7|127|5.8| 9.7| 36| 6900|3.7| no| no| no| good| no|yes|    ckd|\n",
            "| 35|120|1.015|  2|  4|  normal|abnomal|         not present|notpresent|410|214|17.6|132|5.6| 9.5| 44|12100|3.8| no|yes| no| good|yes|yes|    ckd|\n",
            "| 37|130| 1.02|  3|  0|  normal|abnomal|         not present|notpresent|138|182|14.8|133|5.4| 9.3| 33| 4500|3.4|yes| no| no| good| no|yes|    ckd|\n",
            "| 40|130|1.025|  2|  0|abnormal|abnomal|         not present|notpresent| 70|118| 9.4|130|5.4| 8.5| 29|12200|2.6|yes| no| no| good| no|yes|    ckd|\n",
            "| 35|120| 1.01|  2|  4|abnormal|abnomal|         not present|notpresent|490|132| 8.0|130|5.7| 8.0| 28|11000|2.8|yes|yes| no| poor| no|yes|    ckd|\n",
            "| 28|100|1.015|  3|  0|abnormal|abnomal|         not present|notpresent|138|119|11.6|135|4.0| 8.1| 32| 3800|4.3|yes| no| no| good|yes|yes|    ckd|\n",
            "| 60|160| 1.01|  3|  1|  normal| normal|         not present|notpresent| 70| 85| 5.7|142|4.9| 7.8| 28|11400|3.7|yes| no|yes| poor|yes|yes|    ckd|\n",
            "| 20|130|1.015|  2|  0|  normal| normal|         not present|notpresent|380|200|17.5|139|5.3|10.3| 33| 5300|3.2|yes|yes|yes| poor|yes| no|    ckd|\n",
            "| 20|150|1.025|  0|  1|abnormal|abnomal|         not present|   present|208|204|18.4|131|3.7|10.0| 16| 9200|3.6|yes|yes|yes| poor|yes| no|    ckd|\n",
            "| 20|140|1.025|  0|  2|abnormal| normal|         not present|notpresent| 98| 73| 7.3|129|4.9| 9.1| 24| 6200|3.4|yes| no| no| poor|yes|yes|    ckd|\n",
            "| 40|130| 1.02|  0|  0|  normal| normal|         not present|notpresent|157| 78| 6.3|130|5.0|11.7| 37| 6900|5.2| no| no| no| good| no| no|    ckd|\n",
            "| 45|120| 1.02|  3|  0|  normal| normal|         not present|notpresent| 76|119| 6.4|134|4.4|11.6| 30|11400|3.9|yes| no| no| good| no| no|    ckd|\n",
            "| 51|140| 1.02|  2|  0|  normal| normal|             present|notpresent| 99|213| 7.1|135|5.7| 8.4| 24| 5300|4.6|yes|yes|yes| poor| no|yes|    ckd|\n",
            "| 22|120| 1.02|  0|  3|  normal| normal|             present|notpresent|114|204|18.4|129|4.1|11.6| 32| 9200|4.4|yes|yes|yes| good| no| no|    ckd|\n",
            "+---+---+-----+---+---+--------+-------+--------------------+----------+---+---+----+---+---+----+---+-----+---+---+---+---+-----+---+---+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ckd_dataset=df.select(df.age,df.bp,df.al,df.su,df.bgr,df.bu,df.sc,df.sod,df.pot, df.hemo, df.pcv, df.wc,df.rc)\n",
        "ckd_dataset.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AE5zWF17uSlB",
        "outputId": "3b4091a3-503e-419b-ebeb-b7432e0e5a33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+---+---+---+---+----+---+---+----+---+-----+---+\n",
            "|age| bp| al| su|bgr| bu|  sc|sod|pot|hemo|pcv|   wc| rc|\n",
            "+---+---+---+---+---+---+----+---+---+----+---+-----+---+\n",
            "| 40|150|  1|  0|181| 96| 8.4|135|4.0|10.3| 44| 7800|5.2|\n",
            "| 45|140|  4|  0|121| 73| 7.3|130|5.4| 9.4| 38| 6000|3.9|\n",
            "| 16|160|  2|  3|423|111| 7.0|129|4.9|10.6| 31| 7500|4.6|\n",
            "| 18|140|  4|  0|106|119|11.6|131|5.5| 7.2| 32| 6700|4.4|\n",
            "| 51|170|  2|  0| 66|144|16.0|128|5.6| 9.6| 35| 7300|5.0|\n",
            "| 30|160|  3|  0| 74| 84| 9.0|137|4.6| 9.6| 39| 7800|4.0|\n",
            "| 25|170|  0|  0|100|167|14.7|127|5.8| 9.7| 36| 6900|3.7|\n",
            "| 35|120|  2|  4|410|214|17.6|132|5.6| 9.5| 44|12100|3.8|\n",
            "| 37|130|  3|  0|138|182|14.8|133|5.4| 9.3| 33| 4500|3.4|\n",
            "| 40|130|  2|  0| 70|118| 9.4|130|5.4| 8.5| 29|12200|2.6|\n",
            "| 35|120|  2|  4|490|132| 8.0|130|5.7| 8.0| 28|11000|2.8|\n",
            "| 28|100|  3|  0|138|119|11.6|135|4.0| 8.1| 32| 3800|4.3|\n",
            "| 60|160|  3|  1| 70| 85| 5.7|142|4.9| 7.8| 28|11400|3.7|\n",
            "| 20|130|  2|  0|380|200|17.5|139|5.3|10.3| 33| 5300|3.2|\n",
            "| 20|150|  0|  1|208|204|18.4|131|3.7|10.0| 16| 9200|3.6|\n",
            "| 20|140|  0|  2| 98| 73| 7.3|129|4.9| 9.1| 24| 6200|3.4|\n",
            "| 40|130|  0|  0|157| 78| 6.3|130|5.0|11.7| 37| 6900|5.2|\n",
            "| 45|120|  3|  0| 76|119| 6.4|134|4.4|11.6| 30|11400|3.9|\n",
            "| 51|140|  2|  0| 99|213| 7.1|135|5.7| 8.4| 24| 5300|4.6|\n",
            "| 22|120|  0|  3|114|204|18.4|129|4.1|11.6| 32| 9200|4.4|\n",
            "+---+---+---+---+---+---+----+---+---+----+---+-----+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "#indexer = StringIndexer(inputCol=\"predict\", outputCol=\"predict_index\")\n",
        "indexer = StringIndexer(inputCol=\"predict\", outputCol=\"predict_index\")\n",
        "indexed = indexer.fit(df).transform(df)\n",
        "indexed.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ8qRGZCu-yS",
        "outputId": "7d58dec3-2389-4d13-a93c-c82c4a3da540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+-----+---+---+------+-------+--------------------+----------+---+---+----+---+---+----+---+----+---+---+---+---+-----+---+---+-------+-------------+\n",
            "|age| bp|   sg| al| su|   rbc|     pc|                 pcc|        ba|bgr| bu|  sc|sod|pot|hemo|pcv|  wc| rc|htn| dm|cad|appet| pe|ane|predict|predict_index|\n",
            "+---+---+-----+---+---+------+-------+--------------------+----------+---+---+----+---+---+----+---+----+---+---+---+---+-----+---+---+-------+-------------+\n",
            "| 40|150| 1.02|  1|  0|normal| normal|         not present|notpresent|181| 96| 8.4|135|4.0|10.3| 44|7800|5.2|yes|yes| no| good| no| no|    ckd|          0.0|\n",
            "| 45|140| 1.02|  4|  0|normal| normal|not present         |notpresent|121| 73| 7.3|130|5.4| 9.4| 38|6000|3.9| no| no| no| good| no|yes|    ckd|          0.0|\n",
            "| 16|160| 1.02|  2|  3|normal| normal|         not present|notpresent|423|111| 7.0|129|4.9|10.6| 31|7500|4.6| no|yes| no| poor| no| no|    ckd|          0.0|\n",
            "| 18|140|1.005|  4|  0|normal|abnomal|             present|notpresent|106|119|11.6|131|5.5| 7.2| 32|6700|4.4|yes| no| no| poor|yes|yes|    ckd|          0.0|\n",
            "| 51|170| 1.01|  2|  0|normal| normal|             present|notpresent| 66|144|16.0|128|5.6| 9.6| 35|7300|5.0| no| no| no| good| no|yes|    ckd|          0.0|\n",
            "+---+---+-----+---+---+------+-------+--------------------+----------+---+---+----+---+---+----+---+----+---+---+---+---+-----+---+---+-------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = indexed.randomSplit([0.9,0.1])"
      ],
      "metadata": {
        "id": "ZPTxrX1G4MA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assembler=VectorAssembler().setInputCols(['age','bp','sg','al','bgr','bu', 'sc', 'sod','pot','hemo','pcv','wc','rc'])\\\n",
        ".setOutputCol('features')\n",
        "train_a = assembler.transform(train)\n",
        "train_b=train_a.select(\"features\",train_a.predict_index.alias('label'))\n",
        "train_b.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqK5Y9Ti4QRk",
        "outputId": "481ac314-9a75-4d46-fef4-9cccc26653c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------------------------------+-----+\n",
            "|features                                                              |label|\n",
            "+----------------------------------------------------------------------+-----+\n",
            "|[14.0,130.0,1.025,3.0,102.0,171.0,6.1,132.0,5.1,9.6,33.0,5800.0,3.9]  |0.0  |\n",
            "|[15.0,60.0,1.02,0.0,98.0,49.0,0.5,140.0,3.5,14.6,46.0,8100.0,4.6]     |1.0  |\n",
            "|[16.0,120.0,1.005,0.0,101.0,249.0,18.8,127.0,5.8,10.4,37.0,3800.0,4.0]|0.0  |\n",
            "|[18.0,140.0,1.005,4.0,106.0,119.0,11.6,131.0,5.5,7.2,32.0,6700.0,4.4] |0.0  |\n",
            "|[19.0,70.0,1.02,0.0,132.0,18.0,1.1,150.0,4.7,14.4,44.0,4700.0,5.2]    |1.0  |\n",
            "|[19.0,120.0,1.02,2.0,447.0,132.0,8.0,141.0,3.9,15.0,32.0,9200.0,4.4]  |0.0  |\n",
            "|[19.0,130.0,1.01,0.0,298.0,182.0,9.8,130.0,5.6,7.4,46.0,11400.0,2.6]  |0.0  |\n",
            "|[19.0,170.0,1.01,4.0,323.0,117.0,8.4,138.0,4.2,9.1,32.0,9200.0,4.4]   |0.0  |\n",
            "|[20.0,60.0,1.02,0.0,100.0,47.0,0.5,142.0,3.5,14.0,52.0,4500.0,5.5]    |1.0  |\n",
            "|[20.0,70.0,1.02,0.0,133.0,48.0,1.2,147.0,4.3,14.6,44.0,5500.0,4.5]    |1.0  |\n",
            "|[20.0,130.0,1.015,2.0,380.0,200.0,17.5,139.0,5.3,10.3,33.0,5300.0,3.2]|0.0  |\n",
            "|[20.0,140.0,1.02,1.0,91.0,167.0,14.7,131.0,5.5,11.9,31.0,7500.0,4.6]  |0.0  |\n",
            "|[20.0,140.0,1.025,0.0,98.0,73.0,7.3,129.0,4.9,9.1,24.0,6200.0,3.4]    |0.0  |\n",
            "|[20.0,150.0,1.025,0.0,208.0,204.0,18.4,131.0,3.7,10.0,16.0,9200.0,3.6]|0.0  |\n",
            "|[20.0,160.0,1.025,2.0,308.0,190.0,9.3,145.0,3.7,8.1,39.0,6900.0,4.0]  |0.0  |\n",
            "|[21.0,140.0,1.01,2.0,100.0,34.0,5.4,133.0,4.7,10.7,16.0,9200.0,3.6]   |0.0  |\n",
            "|[22.0,70.0,1.02,0.0,117.0,22.0,1.2,138.0,3.5,14.7,50.0,9300.0,6.1]    |1.0  |\n",
            "|[22.0,140.0,1.025,3.0,140.0,138.0,5.4,131.0,4.8,8.6,32.0,6700.0,4.4]  |0.0  |\n",
            "|[23.0,60.0,1.02,0.0,107.0,48.0,0.8,144.0,3.5,16.4,40.0,8300.0,4.8]    |1.0  |\n",
            "|[23.0,80.0,1.02,0.0,130.0,41.0,0.9,141.0,4.4,14.0,42.0,7000.0,5.2]    |1.0  |\n",
            "+----------------------------------------------------------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression()"
      ],
      "metadata": {
        "id": "j8RqEC9v45Nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = lr.fit(train_b)\n",
        "test_a = assembler.transform(test)\n",
        "test_b = test_a.select('features', test_a.predict_index.alias('label'))\n",
        "test_c = model.transform(test_b)\n",
        "test_c.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jeyZaXDJC8Wt",
        "outputId": "2279ac01-6a51-4641-8f9e-8c35eefb5b13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-46af9ec0e3cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massembler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o385.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 22.0 failed 1 times, most recent failure: Lost task 0.0 in stage 22.0 (TID 20) (421e0912d0d3 executor driver): org.apache.spark.SparkException: Failed to execute user defined function (VectorAssembler$$Lambda$3473/0x0000000841410840: (struct<age_double_VectorAssembler_23734e2b3a24:double,bp_double_VectorAssembler_23734e2b3a24:double,sg:double,al_double_VectorAssembler_23734e2b3a24:double,bgr_double_VectorAssembler_23734e2b3a24:double,bu_double_VectorAssembler_23734e2b3a24:double,sc:double,sod_double_VectorAssembler_23734e2b3a24:double,pot:double,hemo:double,pcv_double_VectorAssembler_23734e2b3a24:double,wc_double_VectorAssembler_23734e2b3a24:double,rc:double>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>)\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.failedExecuteUserDefinedFunctionError(QueryExecutionErrors.scala:190)\n\tat org.apache.spark.sql.errors.QueryExecutionErrors.failedExecuteUserDefinedFunctionError(QueryExecutionErrors.scala)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:199)\n\tat scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:192)\n\tat scala.collection.AbstractIterator.foldLeft(Iterator.scala:1431)\n\tat scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:260)\n\tat scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:260)\n\tat scala.collection.AbstractIterator.aggregate(Iterator.scala:1431)\n\tat org.apache.spark.rdd.RDD.$anonfun$treeAggregate$4(RDD.scala:1236)\n\tat org.apache.spark.rdd.RDD.$anonfun$treeAggregate$6(RDD.scala:1237)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:855)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:855)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: org.apache.spark.SparkException: Encountered null while assembling a row with handleInvalid = \"error\". Consider\nremoving nulls from dataset or using handleInvalid = \"keep\" or \"skip\".\n\tat org.apache.spark.ml.feature.VectorAssembler$.$anonfun$assemble$1(VectorAssembler.scala:291)\n\tat org.apache.spark.ml.feature.VectorAssembler$.$anonfun$assemble$1$adapted(VectorAssembler.scala:260)\n\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38)\n\tat org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:260)\n\tat org.apache.spark.ml.feature.VectorAssembler.$anonfun$transform$6(VectorAssembler.scala:143)\n\t... 30 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2238)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2333)\n\tat org.apache.spark.rdd.RDD.$anonfun$fold$1(RDD.scala:1174)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.fold(RDD.scala:1168)\n\tat org.apache.spark.rdd.RDD.$anonfun$treeAggregate$2(RDD.scala:1267)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1228)\n\tat org.apache.spark.rdd.RDD.$anonfun$treeAggregate$1(RDD.scala:1214)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1214)\n\tat org.apache.spark.ml.optim.WeightedLeastSquares.fit(WeightedLeastSquares.scala:107)\n\tat org.apache.spark.ml.regression.LinearRegression.trainWithNormal(LinearRegression.scala:451)\n\tat org.apache.spark.ml.regression.LinearRegression.$anonfun$train$1(LinearRegression.scala:345)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.regression.LinearRegression.train(LinearRegression.scala:327)\n\tat org.apache.spark.ml.regression.LinearRegression.train(LinearRegression.scala:184)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:151)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function (VectorAssembler$$Lambda$3473/0x0000000841410840: (struct<age_double_VectorAssembler_23734e2b3a24:double,bp_double_VectorAssembler_23734e2b3a24:double,sg:double,al_double_VectorAssembler_23734e2b3a24:double,bgr_double_VectorAssembler_23734e2b3a24:double,bu_double_VectorAssembler_23734e2b3a24:double,sc:double,sod_double_VectorAssembler_23734e2b3a24:double,pot:double,hemo:double,pcv_double_VectorAssembler_23734e2b3a24:double,wc_double_VectorAssembler_23734e2b3a24:double,rc:double>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>)\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.failedExecuteUserDefinedFunctionError(QueryExecutionErrors.scala:190)\n\tat org.apache.spark.sql.errors.QueryExecutionErrors.failedExecuteUserDefinedFunctionError(QueryExecutionErrors.scala)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:199)\n\tat scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:192)\n\tat scala.collection.AbstractIterator.foldLeft(Iterator.scala:1431)\n\tat scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:260)\n\tat scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:260)\n\tat scala.collection.AbstractIterator.aggregate(Iterator.scala:1431)\n\tat org.apache.spark.rdd.RDD.$anonfun$treeAggregate$4(RDD.scala:1236)\n\tat org.apache.spark.rdd.RDD.$anonfun$treeAggregate$6(RDD.scala:1237)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:855)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:855)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\nCaused by: org.apache.spark.SparkException: Encountered null while assembling a row with handleInvalid = \"error\". Consider\nremoving nulls from dataset or using handleInvalid = \"keep\" or \"skip\".\n\tat org.apache.spark.ml.feature.VectorAssembler$.$anonfun$assemble$1(VectorAssembler.scala:291)\n\tat org.apache.spark.ml.feature.VectorAssembler$.$anonfun$assemble$1$adapted(VectorAssembler.scala:260)\n\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38)\n\tat org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:260)\n\tat org.apache.spark.ml.feature.VectorAssembler.$anonfun$transform$6(VectorAssembler.scala:143)\n\t... 30 more\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating the model.\n",
        "\n",
        "evaluator = RegressionEvaluator()\n",
        "print(evaluator.evaluate(test_c,\n",
        "{evaluator.metricName: \"r2\"})\n",
        ")\n",
        "print(evaluator.evaluate(test_c,\n",
        "{evaluator.metricName: \"mse\"})\n",
        ")\n",
        "print(evaluator.evaluate(test_c,\n",
        "{evaluator.metricName: \"rmse\"})\n",
        ")\n",
        "print(evaluator.evaluate(test_c,\n",
        "{evaluator.metricName: \"mae\"})\n",
        ")"
      ],
      "metadata": {
        "id": "qFdiDL9gFBlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Building a Decision Tree Model.\n",
        "\n",
        "from pyspark.ml.regression import DecisionTreeRegressor\n",
        "dt = DecisionTreeRegressor()\n",
        "model = dt.fit(train_b)\n",
        "test_dt = model.transform(test_b)\n",
        "test_dt.show(truncate=False)"
      ],
      "metadata": {
        "id": "778cJcijFBZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating the model\n",
        "\n",
        "evaluator = RegressionEvaluator()\n",
        "print(evaluator.evaluate(test_dt,\n",
        "{evaluator.metricName: \"r2\"})\n",
        ")\n",
        "print(evaluator.evaluate(test_dt,\n",
        "{evaluator.metricName: \"mse\"})\n",
        ")\n",
        "print(evaluator.evaluate(test_dt,\n",
        "{evaluator.metricName: \"rmse\"})\n",
        ")\n",
        "print(evaluator.evaluate(test_dt,\n",
        "{evaluator.metricName: \"mae\"})\n",
        ")"
      ],
      "metadata": {
        "id": "L5ynncI0FBQF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}