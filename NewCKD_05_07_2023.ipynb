{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFrO7jomrHYj",
        "outputId": "c76dc149-dba9-4850-f39b-c324d6ce2133"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "openjdk-8-jdk is already the newest version (8u372-ga~us1-0ubuntu1~20.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "#Install Java Development kit for Spark\n",
        "!apt-get install openjdk-8-jdk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "F9Q4hvvks8hR"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "QE6oJChUs8fk"
      },
      "outputs": [],
      "source": [
        "#Set the JAVA_HOME env variable\n",
        "os.environ[\"JAVA_HOME\"]=\"/usr/lib/jvm/java-8-openjdk-amd64\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRjve76ds8d0",
        "outputId": "9bdd1433-2733-4998-bb1a-4d9d6938d245"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "#Current working directory\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw5c4DXbs8a4",
        "outputId": "b4ad0141-6767-4839-a790-1b982f552c6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/jvm/java-8-openjdk-amd64\n"
          ]
        }
      ],
      "source": [
        "!echo $JAVA_HOME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1i6oVQss8Ya",
        "outputId": "7c814175-0fbe-474c-9515-7a3d473ad520"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark==3.0.0 in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.10/dist-packages (from pyspark==3.0.0) (0.10.9)\n"
          ]
        }
      ],
      "source": [
        "#Install PySpark with latest version\n",
        "!pip install pyspark==3.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "OVQt0YWXuI5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f6fe906-5c1f-433b-b6b5-8fa905422523"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: findspark in /usr/local/lib/python3.10/dist-packages (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install findspark\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "xuMziEEEuIwN"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession, SQLContext\n",
        "spark = SparkSession.builder.master(\"local\").appName(\"Test Spark\").config(\"spark.some.config.option\", \"some-value\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "Q8yHIVAY3l3g"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "ewvjwee33nEI",
        "outputId": "a4acfa2a-2bd3-4579-e4cb-f73362705adc"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fe3d83482b0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://d15c064d233c:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.0.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Test Spark</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mount your drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "losHHKsa46jH",
        "outputId": "60ee9f43-e3cc-4c48-dd4c-02a365372083"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "r1f0ksKNs8VX"
      },
      "outputs": [],
      "source": [
        "#Read the csv file\n",
        "df=spark.read.csv('/content/drive/MyDrive/Colab Notebooks/dataset/Dataset_CKD.csv',inferSchema=True,header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YR_ma62Is8Sv",
        "outputId": "aca75f0f-5010-42aa-c798-0e538a9d63b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(34991, 25)\n"
          ]
        }
      ],
      "source": [
        "#Check dimension's\n",
        "print((df.count(),len(df.columns)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcAwea_cs8QU",
        "outputId": "87c315de-c1da-4d99-99f0-94fa715cd6af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- bp: integer (nullable = true)\n",
            " |-- sg: double (nullable = true)\n",
            " |-- al: integer (nullable = true)\n",
            " |-- su: integer (nullable = true)\n",
            " |-- rbc: string (nullable = true)\n",
            " |-- pc: string (nullable = true)\n",
            " |-- pcc: string (nullable = true)\n",
            " |-- ba: string (nullable = true)\n",
            " |-- bgr: integer (nullable = true)\n",
            " |-- bu: double (nullable = true)\n",
            " |-- sc: double (nullable = true)\n",
            " |-- sod: double (nullable = true)\n",
            " |-- pot: double (nullable = true)\n",
            " |-- hemo: double (nullable = true)\n",
            " |-- pcv: integer (nullable = true)\n",
            " |-- wc: integer (nullable = true)\n",
            " |-- rc: double (nullable = true)\n",
            " |-- htn: string (nullable = true)\n",
            " |-- dm: string (nullable = true)\n",
            " |-- cad: string (nullable = true)\n",
            " |-- appet: string (nullable = true)\n",
            " |-- pe: string (nullable = true)\n",
            " |-- ane: string (nullable = true)\n",
            " |-- class: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Check for the schema\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6G_aM0zss8N5",
        "outputId": "c851515b-ba47-41be-d970-aa0e463108f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+-----+---+---+------+-------+--------------------+----------+---+-----+----+-----+---+----+---+----+---+---+---+---+-----+---+---+-----+\n",
            "|age| bp|   sg| al| su|   rbc|     pc|                 pcc|        ba|bgr|   bu|  sc|  sod|pot|hemo|pcv|  wc| rc|htn| dm|cad|appet| pe|ane|class|\n",
            "+---+---+-----+---+---+------+-------+--------------------+----------+---+-----+----+-----+---+----+---+----+---+---+---+---+-----+---+---+-----+\n",
            "| 50|150| 1.02|  1|  0|normal| normal|         not present|notpresent|181| 96.0| 8.4|135.0|4.0|10.3| 44|7800|5.2| no| no| no| good| no| no|  ckd|\n",
            "| 69|140| 1.02|  4|  0|normal| normal|not present         |notpresent|121| 73.0| 7.3|130.0|5.4| 9.4| 38|6000|3.9| no| no| no| good| no|yes|  ckd|\n",
            "| 69|160| 1.02|  2|  3|normal| normal|         not present|notpresent|423|111.0| 7.0|129.0|4.9|10.6| 31|7500|4.6| no|yes| no| poor| no| no|  ckd|\n",
            "| 71|140|1.005|  4|  0|normal|abnomal|             present|notpresent|106|119.0|11.6|131.0|5.5| 7.2| 32|6700|4.4| no| no| no| poor|yes|yes|  ckd|\n",
            "| 65|170| 1.01|  2|  0|normal| normal|             present|notpresent| 66|144.0|16.0|128.0|5.6| 9.6| 35|7300|5.0| no| no| no| good| no|yes|  ckd|\n",
            "+---+---+-----+---+---+------+-------+--------------------+----------+---+-----+----+-----+---+----+---+----+---+---+---+---+-----+---+---+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Top 5 records\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Wie2lZWs8Lx",
        "outputId": "de3fb854-409c-4517-ffe4-3d17d5d648d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('age', 'int'),\n",
              " ('bp', 'int'),\n",
              " ('sg', 'double'),\n",
              " ('al', 'int'),\n",
              " ('su', 'int'),\n",
              " ('rbc', 'string'),\n",
              " ('pc', 'string'),\n",
              " ('pcc', 'string'),\n",
              " ('ba', 'string'),\n",
              " ('bgr', 'int'),\n",
              " ('bu', 'double'),\n",
              " ('sc', 'double'),\n",
              " ('sod', 'double'),\n",
              " ('pot', 'double'),\n",
              " ('hemo', 'double'),\n",
              " ('pcv', 'int'),\n",
              " ('wc', 'int'),\n",
              " ('rc', 'double'),\n",
              " ('htn', 'string'),\n",
              " ('dm', 'string'),\n",
              " ('cad', 'string'),\n",
              " ('appet', 'string'),\n",
              " ('pe', 'string'),\n",
              " ('ane', 'string'),\n",
              " ('class', 'string')]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "#Datatypes of the columns\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "0wq3utJqs8JW"
      },
      "outputs": [],
      "source": [
        "#Drop unwanted columns\n",
        "#my_data = df.drop(*['contact', 'day', 'month','default'])\n",
        "my_data = df.alias('my_data')\n",
        "#my_data = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYTGFHeCs8HG",
        "outputId": "d17a2d4b-2670-42b4-eb7c-b330c43a2284"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34991, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "# get the dimensions of the data\n",
        "(my_data.count() , len(my_data.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwzTlY6Es8Eu",
        "outputId": "a0df17fc-d12e-4bbd-c6e9-f376fcb95034"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+-----------------+--------------------+------------------+------------------+------+-------+-----------+----------+------------------+-----------------+------------------+------------------+------------------+------------------+-----------------+-----------------+------------------+-----+-----+-----+-----+-----+-----+------+\n",
            "|summary|               age|               bp|                  sg|                al|                su|   rbc|     pc|        pcc|        ba|               bgr|               bu|                sc|               sod|               pot|              hemo|              pcv|               wc|                rc|  htn|   dm|  cad|appet|   pe|  ane| class|\n",
            "+-------+------------------+-----------------+--------------------+------------------+------------------+------+-------+-----------+----------+------------------+-----------------+------------------+------------------+------------------+------------------+-----------------+-----------------+------------------+-----+-----+-----+-----+-----+-----+------+\n",
            "|  count|             34624|            34376|               34641|             34645|             34625| 34991|  34514|      34924|     34924|             34895|            34820|             34848|             34923|             34923|             34891|            34926|            34884|             34884|34964|34964|34991|34978|34978|34991| 34991|\n",
            "|   mean| 53.60391635859519|96.03828252269025|   1.017482174302275| 1.134218501948333|0.6310469314079422|  null|   null|       null|      null|156.66445049434017| 97.1250631820793| 5.779862545914541|136.44355295936793| 4.767522835953098| 11.69885414576862|36.96392372444597|8402.801284256393| 4.421585540648705| null| null| null| null| null| null|  null|\n",
            "| stddev|15.763406949949703| 34.5337112220718|0.007260703738802244|1.4491524539251002|1.1794267174510582|  null|   null|       null|      null| 84.18697411826423|72.28518974255873|6.8423242572169025| 9.625824346900608|2.7031236187036902|2.9210305222303066|8.605085050708617|2944.997485571242|0.9813720813184893| null| null| null| null| null| null|  null|\n",
            "|    min|                 2|               10|               1.005|                 0|                 0|normal|abnomal|not present|notpresent|                22|              1.5|               0.4|               4.5|               2.1|               3.1|                9|             2200|               2.1|   no|  \tno|   no|    ?|    ?|   no|   ckd|\n",
            "|    max|                91|              180|               1.025|                 5|                 5|normal| normal|    present|   present|               490|            914.0|              76.0|             198.0|              58.6|              43.0|               98|            26400|               8.0|  yes|  yes|  yes| poor|  yes|  yes|notckd|\n",
            "+-------+------------------+-----------------+--------------------+------------------+------------------+------+-------+-----------+----------+------------------+-----------------+------------------+------------------+------------------+------------------+-----------------+-----------------+------------------+-----+-----+-----+-----+-----+-----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "my_data.describe().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vPTjJTXs8CR",
        "outputId": "3f4efaeb-0ba6-4bd4-d36a-81ecb9128643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+---+---+---+---+---+---+---+---+---+---+---+---+----+---+---+---+---+---+---+-----+---+---+-----+\n",
            "|age| bp| sg| al| su|rbc| pc|pcc| ba|bgr| bu| sc|sod|pot|hemo|pcv| wc| rc|htn| dm|cad|appet| pe|ane|class|\n",
            "+---+---+---+---+---+---+---+---+---+---+---+---+---+---+----+---+---+---+---+---+---+-----+---+---+-----+\n",
            "|367|615|350|346|366|  0|477| 67| 67| 96|171|143| 68| 68| 100| 65|107|107| 27| 27|  0|   13| 13|  0|    0|\n",
            "+---+---+---+---+---+---+---+---+---+---+---+---+---+---+----+---+---+---+---+---+---+-----+---+---+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# import sql function pyspark\n",
        "import pyspark.sql.functions as f\n",
        "\n",
        "# null values in each column\n",
        "data_agg = my_data.agg(*[f.count(f.when(f.isnull(c), c)).alias(c) for c in my_data.columns])\n",
        "data_agg.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "FLBQWcPYs7_o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48431908-fd5e-4536-9265-a15235c1872e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|   rbc|count|\n",
            "+------+-----+\n",
            "|normal|34991|\n",
            "+------+-----+\n",
            "\n",
            "\n",
            "+--------+-----+\n",
            "|      pc|count|\n",
            "+--------+-----+\n",
            "|    null|  477|\n",
            "|  normal|22792|\n",
            "|abnormal|11167|\n",
            "| abnomal|  555|\n",
            "+--------+-----+\n",
            "\n",
            "\n",
            "+--------------------+-----+\n",
            "|                 pcc|count|\n",
            "+--------------------+-----+\n",
            "|             present| 3873|\n",
            "|          notpresent|22315|\n",
            "|                null|   67|\n",
            "|not present         |   28|\n",
            "|         not present| 8708|\n",
            "+--------------------+-----+\n",
            "\n",
            "\n",
            "+----------+-----+\n",
            "|        ba|count|\n",
            "+----------+-----+\n",
            "|   present| 3947|\n",
            "|notpresent|30977|\n",
            "|      null|   67|\n",
            "+----------+-----+\n",
            "\n",
            "\n",
            "+----+-----+\n",
            "| htn|count|\n",
            "+----+-----+\n",
            "|null|   27|\n",
            "|  no|19981|\n",
            "| yes|14983|\n",
            "+----+-----+\n",
            "\n",
            "\n",
            "+----+-----+\n",
            "|  dm|count|\n",
            "+----+-----+\n",
            "|null|   27|\n",
            "|\tyes|  130|\n",
            "| \tno|  170|\n",
            "|  no|21066|\n",
            "| yes|13574|\n",
            "| yes|   24|\n",
            "+----+-----+\n",
            "\n",
            "\n",
            "+---+-----+\n",
            "|cad|count|\n",
            "+---+-----+\n",
            "| no|24779|\n",
            "|yes|10212|\n",
            "+---+-----+\n",
            "\n",
            "\n",
            "+-----+-----+\n",
            "|appet|count|\n",
            "+-----+-----+\n",
            "| null|   13|\n",
            "|good |   79|\n",
            "| poor| 8926|\n",
            "| good|25921|\n",
            "|    ?|   52|\n",
            "+-----+-----+\n",
            "\n",
            "\n",
            "+----+-----+\n",
            "|  pe|count|\n",
            "+----+-----+\n",
            "|null|   13|\n",
            "|  no|26729|\n",
            "| yes| 8238|\n",
            "|   ?|   11|\n",
            "+----+-----+\n",
            "\n",
            "\n",
            "+---+-----+\n",
            "|ane|count|\n",
            "+---+-----+\n",
            "| no|22990|\n",
            "|yes|12001|\n",
            "+---+-----+\n",
            "\n",
            "\n",
            "+------+-----+\n",
            "| class|count|\n",
            "+------+-----+\n",
            "|notckd|10233|\n",
            "|   ckd|24679|\n",
            "|  ckd\t|   79|\n",
            "+------+-----+\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# value counts of columns\n",
        "my_data.groupBy('rbc').count().show()\n",
        "print()\n",
        "my_data.groupBy('pc').count().show()\n",
        "print()\n",
        "my_data.groupBy('pcc').count().show()\n",
        "print()\n",
        "my_data.groupBy('ba').count().show()\n",
        "print()\n",
        "my_data.groupBy('htn').count().show()\n",
        "print()\n",
        "my_data.groupBy('dm').count().show()\n",
        "print()\n",
        "my_data.groupBy('cad').count().show()\n",
        "print()\n",
        "my_data.groupBy('appet').count().show()\n",
        "print()\n",
        "my_data.groupBy('pe').count().show()\n",
        "print()\n",
        "my_data.groupBy('ane').count().show()\n",
        "print()\n",
        "my_data.groupBy('class').count().show()\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2tdizyc0QAt",
        "outputId": "f6e4bbc4-5f0f-439b-af2e-1e980bd2ccd3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('age', 'int'),\n",
              " ('bp', 'int'),\n",
              " ('sg', 'double'),\n",
              " ('al', 'int'),\n",
              " ('su', 'int'),\n",
              " ('rbc', 'string'),\n",
              " ('pc', 'string'),\n",
              " ('pcc', 'string'),\n",
              " ('ba', 'string'),\n",
              " ('bgr', 'int'),\n",
              " ('bu', 'double'),\n",
              " ('sc', 'double'),\n",
              " ('sod', 'double'),\n",
              " ('pot', 'double'),\n",
              " ('hemo', 'double'),\n",
              " ('pcv', 'int'),\n",
              " ('wc', 'int'),\n",
              " ('rc', 'double'),\n",
              " ('htn', 'string'),\n",
              " ('dm', 'string'),\n",
              " ('cad', 'string'),\n",
              " ('appet', 'string'),\n",
              " ('pe', 'string'),\n",
              " ('ane', 'string'),\n",
              " ('class', 'string')]"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "my_data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "F0krivrR0P49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9d9f385-9438-4a50-e4cb-6d1b63932893"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['age',\n",
              " 'bp',\n",
              " 'sg',\n",
              " 'al',\n",
              " 'su',\n",
              " 'rbc',\n",
              " 'pc',\n",
              " 'pcc',\n",
              " 'ba',\n",
              " 'bgr',\n",
              " 'bu',\n",
              " 'sc',\n",
              " 'sod',\n",
              " 'pot',\n",
              " 'hemo',\n",
              " 'pcv',\n",
              " 'wc',\n",
              " 'rc',\n",
              " 'htn',\n",
              " 'dm',\n",
              " 'cad',\n",
              " 'appet',\n",
              " 'pe',\n",
              " 'ane',\n",
              " 'class']"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "my_data.columns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing steps\n",
        "# import packages\n",
        "# from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
        "# # conversion\n",
        "# indexer = StringIndexer(inputCol='feature1', outputCol='feature1_numeric').fit(spark_df)\n",
        "# indexed_df = indexer.transform(spark_df)\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
        "\n",
        "# create object of StringIndexer class and specify input and output column\n",
        "SI_rbc = StringIndexer(inputCol='rbc',outputCol='rbc_Index')\n",
        "SI_pc = StringIndexer(inputCol='pc',outputCol='pc_Index')\n",
        "SI_pcc = StringIndexer(inputCol='pcc',outputCol='pcc_Index')\n",
        "SI_ba = StringIndexer(inputCol='ba',outputCol='ba_Index')\n",
        "SI_htn = StringIndexer(inputCol='htn',outputCol='htn_Index')\n",
        "SI_dm = StringIndexer(inputCol='dm',outputCol='dm_Index')\n",
        "SI_cad = StringIndexer(inputCol='cad',outputCol='cad_Index')\n",
        "SI_appet = StringIndexer(inputCol='appet',outputCol='appet_Index')\n",
        "SI_pe = StringIndexer(inputCol='pe',outputCol='pe_Index')\n",
        "SI_ane = StringIndexer(inputCol='ane',outputCol='ane_Index')\n",
        "SI_predict = StringIndexer(inputCol='class',outputCol='predict_Index')\n",
        "\n",
        "# transform the data\n",
        "my_data = SI_rbc.fit(my_data).transform(my_data)\n",
        "my_data = SI_pc.fit(my_data).transform(my_data)\n",
        "my_data = SI_pcc.fit(my_data).transform(my_data)\n",
        "my_data = SI_ba.fit(my_data).transform(my_data)\n",
        "my_data = SI_htn.fit(my_data).transform(my_data)\n",
        "my_data = SI_dm.fit(my_data).transform(my_data)\n",
        "my_data = SI_cad.fit(my_data).transform(my_data)\n",
        "my_data = SI_appet.fit(my_data).transform(my_data)\n",
        "my_data = SI_pe.fit(my_data).transform(my_data)\n",
        "my_data = SI_ane.fit(my_data).transform(my_data)\n",
        "my_data = SI_predict.fit(my_data).transform(my_data)"
      ],
      "metadata": {
        "id": "IFc0UiedNU9D"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_data.select('rbc', 'rbc_Index', 'pc', 'pc_Index', 'pcc', 'pcc_Index', 'ba', 'ba_Index', 'htn', 'htn_Index', 'dm', 'dm_Index', 'cad', 'cad_Index', 'appet', 'appet_Index', 'pe', 'pe_Index', 'ane', 'ane_Index', 'class', 'predict_Index').show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NaTF_ybQATJ",
        "outputId": "53b73ef7-afa0-4961-db20-e06e47362620"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------+-------+--------+--------------------+---------+----------+--------+---+---------+---+--------+---+---------+-----+-----------+---+--------+---+---------+-----+-------------+\n",
            "|   rbc|rbc_Index|     pc|pc_Index|                 pcc|pcc_Index|        ba|ba_Index|htn|htn_Index| dm|dm_Index|cad|cad_Index|appet|appet_Index| pe|pe_Index|ane|ane_Index|class|predict_Index|\n",
            "+------+---------+-------+--------+--------------------+---------+----------+--------+---+---------+---+--------+---+---------+-----+-----------+---+--------+---+---------+-----+-------------+\n",
            "|normal|      0.0| normal|     0.0|         not present|      1.0|notpresent|     0.0| no|      0.0| no|     0.0| no|      0.0| good|        0.0| no|     0.0| no|      0.0|  ckd|          0.0|\n",
            "|normal|      0.0| normal|     0.0|not present         |      3.0|notpresent|     0.0| no|      0.0| no|     0.0| no|      0.0| good|        0.0| no|     0.0|yes|      1.0|  ckd|          0.0|\n",
            "|normal|      0.0| normal|     0.0|         not present|      1.0|notpresent|     0.0| no|      0.0|yes|     1.0| no|      0.0| poor|        1.0| no|     0.0| no|      0.0|  ckd|          0.0|\n",
            "|normal|      0.0|abnomal|     2.0|             present|      2.0|notpresent|     0.0| no|      0.0| no|     0.0| no|      0.0| poor|        1.0|yes|     1.0|yes|      1.0|  ckd|          0.0|\n",
            "|normal|      0.0| normal|     0.0|             present|      2.0|notpresent|     0.0| no|      0.0| no|     0.0| no|      0.0| good|        0.0| no|     0.0|yes|      1.0|  ckd|          0.0|\n",
            "|normal|      0.0| normal|     0.0|         not present|      1.0|notpresent|     0.0|yes|      1.0| no|     0.0| no|      0.0| good|        0.0|yes|     1.0|yes|      1.0|  ckd|          0.0|\n",
            "|normal|      0.0| normal|     0.0|         not present|      1.0|notpresent|     0.0| no|      0.0| no|     0.0| no|      0.0| good|        0.0| no|     0.0|yes|      1.0|  ckd|          0.0|\n",
            "|normal|      0.0|abnomal|     2.0|         not present|      1.0|notpresent|     0.0| no|      0.0|yes|     1.0| no|      0.0| good|        0.0|yes|     1.0|yes|      1.0|  ckd|          0.0|\n",
            "|normal|      0.0|abnomal|     2.0|         not present|      1.0|notpresent|     0.0|yes|      1.0| no|     0.0| no|      0.0| good|        0.0| no|     0.0|yes|      1.0|  ckd|          0.0|\n",
            "|normal|      0.0|abnomal|     2.0|         not present|      1.0|notpresent|     0.0|yes|      1.0| no|     0.0| no|      0.0| good|        0.0| no|     0.0|yes|      1.0|  ckd|          0.0|\n",
            "+------+---------+-------+--------+--------------------+---------+----------+--------+---+---------+---+--------+---+---------+-----+-----------+---+--------+---+---------+-----+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "6jWj6KUW0P2e"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# specify the input and output columns of the vector assembler\n",
        "assembler = VectorAssembler(inputCols=['age',\n",
        "                                       'bp',\n",
        "                                       'rbc_Index',\n",
        "                                       'pc_Index',\n",
        "                                       'pcc_Index',\n",
        "                                       'ba_Index',\n",
        "                                       'bgr',\n",
        "                                       'bu',\n",
        "                                       'sc',\n",
        "                                       'sod',\n",
        "                                       'pot',\n",
        "                                       'hemo',\n",
        "                                       'pcv',\n",
        "                                       'wc',\n",
        "                                       'rc',\n",
        "                                       'htn_Index',\n",
        "                                       'dm_Index',\n",
        "                                       'cad_Index',\n",
        "                                       'appet_Index',\n",
        "                                       'pe_Index',\n",
        "                                       'ane_Index'\n",
        "                                       ],\n",
        "                           outputCol='features')\n",
        "\n",
        "# fill the null values\n",
        "my_data = my_data.fillna(0)\n",
        "\n",
        "# transform the data\n",
        "final_data = assembler.transform(my_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "-nYmEbZ10Pz3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7d35f90-6877-4c76-b1d5-7bd3bc78acab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------+\n",
            "|            features|predict_Index|\n",
            "+--------------------+-------------+\n",
            "|(21,[0,1,4,6,7,8,...|          0.0|\n",
            "|[69.0,140.0,0.0,0...|          0.0|\n",
            "|[69.0,160.0,0.0,0...|          0.0|\n",
            "|[71.0,140.0,0.0,2...|          0.0|\n",
            "|[65.0,170.0,0.0,0...|          0.0|\n",
            "|[70.0,160.0,0.0,0...|          0.0|\n",
            "|[35.0,170.0,0.0,0...|          0.0|\n",
            "|[55.0,120.0,0.0,2...|          0.0|\n",
            "|[59.0,130.0,0.0,2...|          0.0|\n",
            "|[55.0,130.0,0.0,2...|          0.0|\n",
            "|[43.0,120.0,0.0,2...|          0.0|\n",
            "|[68.0,100.0,0.0,2...|          0.0|\n",
            "|[68.0,160.0,0.0,0...|          0.0|\n",
            "|[53.0,130.0,0.0,0...|          0.0|\n",
            "|[50.0,150.0,0.0,2...|          0.0|\n",
            "|[69.0,140.0,0.0,0...|          0.0|\n",
            "|(21,[0,1,4,6,7,8,...|          0.0|\n",
            "|[71.0,120.0,0.0,0...|          0.0|\n",
            "|[65.0,140.0,0.0,0...|          0.0|\n",
            "|[70.0,120.0,0.0,0...|          0.0|\n",
            "+--------------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# view the transformed vector\n",
        "final_data.select('features','predict_Index').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy9LB-c20PxM",
        "outputId": "ef9eb19d-c332-4604-a720-9af9b3f1f604"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- features: vector (nullable = true)\n",
            " |-- label: double (nullable = false)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Model_Dataframe\n",
        "model_df = final_data.select(['features','predict_Index'])\n",
        "model_df = model_df.withColumnRenamed(\"predict_Index\",\"label\")\n",
        "model_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "dktB_Luajbkb"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Split into training & testing Dataframe\n",
        "training_df,test_df = model_df.randomSplit([0.75,0.25])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a logistic regression model object\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "log_reg=LogisticRegression().fit(training_df)"
      ],
      "metadata": {
        "id": "6jlFJEna7qAs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1231c98c-dbfb-4f9b-99e7-1ae3d3f0bf45"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-584ed7916819>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Create a logistic regression model object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlog_reg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \"\"\"\n\u001b[1;32m    317\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o2138.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 507.0 failed 1 times, most recent failure: Lost task 0.0 in stage 507.0 (TID 8378, d15c064d233c, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(StringIndexerModel$$Lambda$3024/572994953: (string) => double)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.sort_addToSorter_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:311)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:313)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: StringIndexer encountered NULL value. To handle or skip NULLS, try setting StringIndexer.handleInvalid.\n\tat org.apache.spark.ml.feature.StringIndexerModel.$anonfun$getIndexer$1(StringIndexer.scala:395)\n\tat org.apache.spark.ml.feature.StringIndexerModel.$anonfun$getIndexer$1$adapted(StringIndexer.scala:390)\n\t... 26 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2023)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:1972)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:1971)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1971)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:950)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:950)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:950)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2203)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2152)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2141)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:752)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2093)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2188)\n\tat org.apache.spark.rdd.RDD.$anonfun$fold$1(RDD.scala:1157)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\n\tat org.apache.spark.rdd.RDD.fold(RDD.scala:1151)\n\tat org.apache.spark.rdd.RDD.$anonfun$treeAggregate$1(RDD.scala:1220)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\n\tat org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1196)\n\tat org.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:504)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:492)\n\tat org.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:487)\n\tat org.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:277)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:150)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function(StringIndexerModel$$Lambda$3024/572994953: (string) => double)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.sort_addToSorter_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:311)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:313)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: org.apache.spark.SparkException: StringIndexer encountered NULL value. To handle or skip NULLS, try setting StringIndexer.handleInvalid.\n\tat org.apache.spark.ml.feature.StringIndexerModel.$anonfun$getIndexer$1(StringIndexer.scala:395)\n\tat org.apache.spark.ml.feature.StringIndexerModel.$anonfun$getIndexer$1$adapted(StringIndexer.scala:390)\n\t... 26 more\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_summary=log_reg.summary"
      ],
      "metadata": {
        "id": "tqwrivV17p92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "cffbff7d-28fe-4e9f-acf7-b0b216f635b5"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-3f5de3cdc107>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlr_summary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'log_reg' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Overall accuracy of the classification model\n",
        "lr_summary.accuracy"
      ],
      "metadata": {
        "id": "d_DNJu8C7p6D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54649b63-87dd-4013-f1fb-2c6d4dcd4637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Precision of both classes\n",
        "print(lr_summary.precisionByLabel)"
      ],
      "metadata": {
        "id": "qjWvI9tJ7p2w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dc9c170-c240-466d-c679-05654a5ecdd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.0, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get Preditions\n",
        "predictions = log_reg.transform(test_df)"
      ],
      "metadata": {
        "id": "1cNfpCza7py_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "predictions.select('label','prediction').show(50)"
      ],
      "metadata": {
        "id": "iECKtBrI7pwT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39eccf8d-adb8-4c68-e045-6fdb0fce05e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+\n",
            "|label|prediction|\n",
            "+-----+----------+\n",
            "|    1|       1.0|\n",
            "|    1|       1.0|\n",
            "|    1|       1.0|\n",
            "|    1|       1.0|\n",
            "|    1|       1.0|\n",
            "|    1|       1.0|\n",
            "|    1|       1.0|\n",
            "|    0|       0.0|\n",
            "|    1|       1.0|\n",
            "|    1|       1.0|\n",
            "|    1|       1.0|\n",
            "|    1|       1.0|\n",
            "|    1|       1.0|\n",
            "|    1|       1.0|\n",
            "|    1|       1.0|\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    1|       1.0|\n",
            "|    0|       0.0|\n",
            "|    1|       1.0|\n",
            "|    0|       0.0|\n",
            "|    1|       1.0|\n",
            "|    1|       1.0|\n",
            "|    1|       1.0|\n",
            "|    1|       1.0|\n",
            "|    1|       1.0|\n",
            "|    1|       1.0|\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    1|       1.0|\n",
            "|    1|       1.0|\n",
            "|    1|       1.0|\n",
            "|    1|       1.0|\n",
            "|    1|       1.0|\n",
            "|    1|       1.0|\n",
            "|    1|       1.0|\n",
            "|    0|       0.0|\n",
            "|    1|       1.0|\n",
            "|    1|       1.0|\n",
            "|    1|       1.0|\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    1|       1.0|\n",
            "|    0|       0.0|\n",
            "|    1|       1.0|\n",
            "|    1|       1.0|\n",
            "|    1|       1.0|\n",
            "|    0|       0.0|\n",
            "+-----+----------+\n",
            "only showing top 50 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import DecisionTreeRegressor\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "metadata": {
        "id": "v0_wwJHv7psr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg=DecisionTreeRegressor().fit(training_df)"
      ],
      "metadata": {
        "id": "qN36IE197pps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "H3Bjp5w17pmW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90262a40-a72f-45fa-ec72-0b2b545f1019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------------------------------------------------------------------------------+-----+\n",
            "|features                                                                                                              |label|\n",
            "+----------------------------------------------------------------------------------------------------------------------+-----+\n",
            "|(24,[0,1,2,3,4,9,10,11,12,13,14,15,16,17],[42.0,170.0,1.005,4.0,2.0,109.0,204.0,18.4,131.0,5.5,10.9,24.0,5300.0,4.6]) |1    |\n",
            "|(24,[0,1,2,4,8,9,10,11,12,13,14,15,16,17],[61.0,150.0,1.025,2.0,1.0,129.0,153.0,10.5,130.0,5.6,10.7,33.0,12100.0,5.2])|1    |\n",
            "|(24,[0,1,2,5,9,10,11,12,13,14,15,16,17,18],[38.0,170.0,1.025,1.0,273.0,102.0,7.1,135.0,4.0,12.9,36.0,6900.0,3.7,1.0]) |1    |\n",
            "|(24,[0,1,2,7,9,10,11,12,13,14,15,16,17,19],[29.0,130.0,1.025,1.0,153.0,158.0,8.0,145.0,4.9,11.9,42.0,5300.0,5.0,1.0]) |1    |\n",
            "|[18.0,140.0,1.005,4.0,0.0,1.0,0.0,1.0,0.0,106.0,119.0,11.6,131.0,5.5,7.2,32.0,6700.0,4.4,1.0,0.0,0.0,0.0,1.0,1.0]     |1    |\n",
            "|[18.0,160.0,1.005,0.0,0.0,1.0,0.0,0.0,0.0,250.0,105.0,5.6,130.0,4.5,10.1,29.0,7100.0,3.4,1.0,1.0,0.0,1.0,0.0,0.0]     |1    |\n",
            "|[19.0,120.0,1.02,2.0,0.0,1.0,1.0,0.0,0.0,447.0,132.0,8.0,141.0,3.9,15.0,32.0,9200.0,4.4,1.0,1.0,0.0,1.0,0.0,0.0]      |1    |\n",
            "|[20.0,70.0,1.02,0.0,0.0,1.0,1.0,0.0,0.0,133.0,48.0,1.2,147.0,4.3,14.6,44.0,5500.0,4.5,0.0,0.0,0.0,1.0,0.0,0.0]        |0    |\n",
            "|[22.0,120.0,1.02,0.0,3.0,1.0,1.0,1.0,0.0,114.0,204.0,18.4,129.0,4.1,11.6,32.0,9200.0,4.4,1.0,1.0,1.0,1.0,0.0,0.0]     |1    |\n",
            "|[23.0,150.0,1.01,0.0,1.0,1.0,1.0,0.0,0.0,255.0,249.0,5.9,135.0,5.5,10.3,29.0,8300.0,5.2,1.0,1.0,0.0,0.0,0.0,0.0]      |1    |\n",
            "|[23.0,170.0,1.025,1.0,3.0,0.0,0.0,0.0,0.0,208.0,204.0,5.9,130.0,5.6,8.4,33.0,5300.0,3.2,1.0,1.0,0.0,0.0,1.0,1.0]      |1    |\n",
            "|[24.0,160.0,1.005,0.0,1.0,1.0,0.0,0.0,0.0,138.0,182.0,14.8,133.0,5.4,7.1,36.0,6900.0,3.7,0.0,0.0,0.0,1.0,0.0,1.0]     |1    |\n",
            "|[25.0,120.0,1.02,2.0,4.0,1.0,1.0,1.0,0.0,131.0,249.0,5.2,130.0,5.3,7.0,37.0,6900.0,5.2,1.0,0.0,0.0,1.0,1.0,1.0]       |1    |\n",
            "|[25.0,150.0,1.01,4.0,2.0,0.0,0.0,0.0,0.0,76.0,167.0,14.7,131.0,5.5,7.9,37.0,6900.0,5.2,1.0,0.0,0.0,1.0,1.0,1.0]       |1    |\n",
            "|[25.0,150.0,1.02,0.0,1.0,1.0,0.0,0.0,1.0,91.0,190.0,9.7,130.0,4.2,10.6,44.0,11000.0,5.0,1.0,0.0,0.0,1.0,0.0,0.0]      |1    |\n",
            "|[28.0,60.0,1.02,0.0,0.0,1.0,1.0,0.0,0.0,130.0,37.0,0.9,150.0,5.0,15.9,48.0,7200.0,6.5,0.0,0.0,0.0,1.0,0.0,0.0]        |0    |\n",
            "|[28.0,70.0,1.025,0.0,0.0,1.0,1.0,0.0,0.0,88.0,50.0,0.6,147.0,3.7,15.4,49.0,8300.0,4.6,0.0,0.0,0.0,1.0,0.0,0.0]        |0    |\n",
            "|[28.0,100.0,1.015,3.0,0.0,0.0,0.0,0.0,0.0,138.0,119.0,11.6,135.0,4.0,8.1,32.0,3800.0,4.3,1.0,0.0,0.0,1.0,1.0,1.0]     |1    |\n",
            "|[29.0,70.0,1.02,0.0,0.0,1.0,1.0,0.0,0.0,78.0,17.0,0.4,147.0,4.7,16.9,46.0,8400.0,6.1,0.0,0.0,0.0,1.0,0.0,0.0]         |0    |\n",
            "|[29.0,150.0,1.01,0.0,0.0,0.0,1.0,0.0,0.0,84.0,143.0,6.2,141.0,5.0,8.1,29.0,12200.0,2.6,1.0,0.0,0.0,1.0,0.0,1.0]       |1    |\n",
            "+----------------------------------------------------------------------------------------------------------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get Preditions\n",
        "predictions = log_reg.transform(test_df)"
      ],
      "metadata": {
        "id": "2u1wTGcB7pf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sfs5XY0kn5zc",
        "outputId": "4ab37c9e-5270-4f35-9058-4c79f990064f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+----------+\n",
            "|            features|label|prediction|\n",
            "+--------------------+-----+----------+\n",
            "|(24,[0,1,2,3,4,9,...|    1|       1.0|\n",
            "|(24,[0,1,2,4,8,9,...|    1|       1.0|\n",
            "|(24,[0,1,2,5,9,10...|    1|       1.0|\n",
            "|(24,[0,1,2,7,9,10...|    1|       1.0|\n",
            "|[18.0,140.0,1.005...|    1|       1.0|\n",
            "|[18.0,160.0,1.005...|    1|       1.0|\n",
            "|[19.0,120.0,1.02,...|    1|       1.0|\n",
            "|[20.0,70.0,1.02,0...|    0|       0.0|\n",
            "|[22.0,120.0,1.02,...|    1|       1.0|\n",
            "|[23.0,150.0,1.01,...|    1|       1.0|\n",
            "|[23.0,170.0,1.025...|    1|       1.0|\n",
            "|[24.0,160.0,1.005...|    1|       1.0|\n",
            "|[25.0,120.0,1.02,...|    1|       1.0|\n",
            "|[25.0,150.0,1.01,...|    1|       1.0|\n",
            "|[25.0,150.0,1.02,...|    1|       1.0|\n",
            "|[28.0,60.0,1.02,0...|    0|       0.0|\n",
            "|[28.0,70.0,1.025,...|    0|       0.0|\n",
            "|[28.0,100.0,1.015...|    1|       1.0|\n",
            "|[29.0,70.0,1.02,0...|    0|       0.0|\n",
            "|[29.0,150.0,1.01,...|    1|       1.0|\n",
            "+--------------------+-----+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\",\n",
        "                                                metricName=\"accuracy\").evaluate(predictions)"
      ],
      "metadata": {
        "id": "LyhhFJXXn_mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dXfZwuEo7S6",
        "outputId": "2115d5c3-0f8c-4909-d630-0619813c7ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest\n",
        "from pyspark.ml.classification import RandomForestClassifier"
      ],
      "metadata": {
        "id": "s7DsxsNfpVS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_classififer = RandomForestClassifier(labelCol=\"label\",\n",
        "                                        numTrees=50).fit(training_df)"
      ],
      "metadata": {
        "id": "Z2mXxEsppelV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_prediction = rf_classififer.transform(test_df)"
      ],
      "metadata": {
        "id": "qZYGPu-crXZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_prediction.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4J_l0DGsAXJ",
        "outputId": "cd9088be-22c1-494c-980b-2e24deecfd9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+-------------+-----------+----------+\n",
            "|            features|label|rawPrediction|probability|prediction|\n",
            "+--------------------+-----+-------------+-----------+----------+\n",
            "|(24,[0,1,2,3,4,9,...|    1|   [0.0,50.0]|  [0.0,1.0]|       1.0|\n",
            "|(24,[0,1,2,4,8,9,...|    1|   [0.0,50.0]|  [0.0,1.0]|       1.0|\n",
            "|(24,[0,1,2,5,9,10...|    1|   [0.0,50.0]|  [0.0,1.0]|       1.0|\n",
            "|(24,[0,1,2,7,9,10...|    1|   [0.0,50.0]|  [0.0,1.0]|       1.0|\n",
            "|[18.0,140.0,1.005...|    1|   [0.0,50.0]|  [0.0,1.0]|       1.0|\n",
            "|[18.0,160.0,1.005...|    1|   [0.0,50.0]|  [0.0,1.0]|       1.0|\n",
            "|[19.0,120.0,1.02,...|    1|   [2.0,48.0]|[0.04,0.96]|       1.0|\n",
            "|[20.0,70.0,1.02,0...|    0|   [50.0,0.0]|  [1.0,0.0]|       0.0|\n",
            "|[22.0,120.0,1.02,...|    1|   [0.0,50.0]|  [0.0,1.0]|       1.0|\n",
            "|[23.0,150.0,1.01,...|    1|   [0.0,50.0]|  [0.0,1.0]|       1.0|\n",
            "|[23.0,170.0,1.025...|    1|   [0.0,50.0]|  [0.0,1.0]|       1.0|\n",
            "|[24.0,160.0,1.005...|    1|   [0.0,50.0]|  [0.0,1.0]|       1.0|\n",
            "|[25.0,120.0,1.02,...|    1|   [0.0,50.0]|  [0.0,1.0]|       1.0|\n",
            "|[25.0,150.0,1.01,...|    1|   [0.0,50.0]|  [0.0,1.0]|       1.0|\n",
            "|[25.0,150.0,1.02,...|    1|   [0.0,50.0]|  [0.0,1.0]|       1.0|\n",
            "|[28.0,60.0,1.02,0...|    0|   [50.0,0.0]|  [1.0,0.0]|       0.0|\n",
            "|[28.0,70.0,1.025,...|    0|   [50.0,0.0]|  [1.0,0.0]|       0.0|\n",
            "|[28.0,100.0,1.015...|    1|   [0.0,50.0]|  [0.0,1.0]|       1.0|\n",
            "|[29.0,70.0,1.02,0...|    0|   [50.0,0.0]|  [1.0,0.0]|       0.0|\n",
            "|[29.0,150.0,1.01,...|    1|   [0.0,50.0]|  [0.0,1.0]|       1.0|\n",
            "+--------------------+-----+-------------+-----------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
      ],
      "metadata": {
        "id": "vkNlt2X0qJpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_acu = BinaryClassificationEvaluator(labelCol=\"label\").evaluate(rf_prediction)"
      ],
      "metadata": {
        "id": "vkiOgCknqJmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_acu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgpuVHTCqJkQ",
        "outputId": "eb29813e-73f3-4ee8-8279-e166d7a7c0d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIWG6SXIsgHT",
        "outputId": "710bfcf1-faea-4e85-de68-bb013e5d2fd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['age',\n",
              " 'bp',\n",
              " 'sg',\n",
              " 'al',\n",
              " 'su',\n",
              " 'rbc',\n",
              " 'pc',\n",
              " 'pcc',\n",
              " 'ba',\n",
              " 'bgr',\n",
              " 'bu',\n",
              " 'sc',\n",
              " 'sod',\n",
              " 'pot',\n",
              " 'hemo',\n",
              " 'pcv',\n",
              " 'wc',\n",
              " 'rc',\n",
              " 'htn',\n",
              " 'dm',\n",
              " 'cad',\n",
              " 'appet',\n",
              " 'pe',\n",
              " 'ane',\n",
              " 'predict']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_classififer.featureImportances"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXTDDNE6qJex",
        "outputId": "1f46654c-f2aa-476a-84ca-f33b877d3071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SparseVector(24, {1: 0.2369, 2: 0.0005, 3: 0.0006, 6: 0.0007, 8: 0.0003, 9: 0.0006, 10: 0.2059, 11: 0.2673, 12: 0.0092, 13: 0.0177, 14: 0.1085, 15: 0.0972, 17: 0.0303, 18: 0.018, 20: 0.0015, 21: 0.0022, 22: 0.001, 23: 0.0015})"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}